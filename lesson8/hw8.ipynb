{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw8.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1tA5oQHySIi1BNCzGJqpaDDJIP7th1NML",
      "authorship_tag": "ABX9TyOAcUO/pvsLQV/m7WRQFoE4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dTenebrae/nlp/blob/main/lesson8/hw8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_0CSuScbYOu"
      },
      "source": [
        "### Задание\n",
        "\n",
        "На вебинаре мы говорили что долгое время CNN и RNN архитектуры были конурируещими выяснить какая архитектура больше подходит для задачи сантимент анализа на данных с вебинара\n",
        "1. построить свёрточные архитектуры\n",
        "2. построить различные архитектуры с RNN\n",
        "3. построить совместные архитектуры CNN -> RNN и (RNN -> CNN)\n",
        "4. сделать выводы что получилось лучше"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbraw43RdnZY"
      },
      "source": [
        "from IPython.display import clear_output"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsVD4tj1deqE"
      },
      "source": [
        "!pip install stop_words\n",
        "!pip install pymorphy2\n",
        "clear_output()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pz_GT-N-dO6M"
      },
      "source": [
        "import pandas as pd\n",
        "from string import punctuation\n",
        "from stop_words import get_stop_words\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Activation, Input, Embedding, Conv1D, GlobalMaxPool1D, SimpleRNN, LSTM, GRU, Masking, MaxPooling1D, Flatten\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.callbacks import TensorBoard \n",
        "from keras.metrics import categorical_crossentropy\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(\"ignore\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keBmSByAdP1x"
      },
      "source": [
        "df_train = pd.read_csv(\"/content/drive/MyDrive/csv/nlp_hw7_data/train.csv\")\n",
        "df_test = pd.read_csv(\"/content/drive/MyDrive/csv/nlp_hw7_data/test.csv\")\n",
        "df_val = pd.read_csv(\"/content/drive/MyDrive/csv/nlp_hw7_data/val.csv\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nVBiPiURtAe"
      },
      "source": [
        "result = []"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFJRsNJ6eepv"
      },
      "source": [
        "sw = set(get_stop_words(\"ru\"))\n",
        "exclude = set(punctuation)\n",
        "morpher = MorphAnalyzer()\n",
        "\n",
        "def preprocess_text(txt):\n",
        "    txt = str(txt)\n",
        "    txt = \"\".join(c for c in txt if c not in exclude)\n",
        "    txt = txt.lower()\n",
        "    txt = re.sub(\"\\sне\", \"не\", txt)\n",
        "    txt = [morpher.parse(word)[0].normal_form for word in txt.split() if word not in sw]\n",
        "    return \" \".join(txt)\n",
        "\n",
        "df_train['text'] = df_train['text'].apply(preprocess_text)\n",
        "df_val['text'] = df_val['text'].apply(preprocess_text)\n",
        "df_test['text'] = df_test['text'].apply(preprocess_text)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1XalSEmetvs"
      },
      "source": [
        "text_corpus_train = df_train['text'].values\n",
        "text_corpus_valid = df_val['text'].values\n",
        "text_corpus_test = df_test['text'].values"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ge6StfBzetye"
      },
      "source": [
        "tokenizer = Tokenizer(num_words=None, \n",
        "                     filters='#$%&()*+-<=>@[\\\\]^_`{|}~\\t\\n',\n",
        "                     lower = False, split = ' ')\n",
        "tokenizer.fit_on_texts(text_corpus_train)\n",
        "\n",
        "sequences_train = tokenizer.texts_to_sequences(text_corpus_train)\n",
        "sequences_val = tokenizer.texts_to_sequences(text_corpus_valid)\n",
        "sequences_test = tokenizer.texts_to_sequences(text_corpus_test)\n",
        "\n",
        "word_count = len(tokenizer.index_word) + 1\n",
        "training_length = max([len(i.split()) for i in text_corpus_train])\n",
        "\n",
        "X_train = pad_sequences(sequences_train, maxlen=training_length)\n",
        "X_valid = pad_sequences(sequences_val, maxlen=training_length)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nW_tFjqdet1I"
      },
      "source": [
        "y_train = df_train['class'].values\n",
        "y_val = df_val['class'].values"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnKQ6wicQ4Hm"
      },
      "source": [
        "### Варианты рекуррентных сетей"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpI8SyGlRAfp"
      },
      "source": [
        "**Простая**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ofjcongcet3k"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(\n",
        "    Embedding(input_dim=word_count,\n",
        "              input_length=training_length,\n",
        "              output_dim=30,\n",
        "              trainable=True,\n",
        "              mask_zero=True))\n",
        "model.add(Masking(mask_value=0.0))\n",
        "\n",
        "model.add(SimpleRNN(64))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h66PRUSte_hW",
        "outputId": "3b9651c2-3573-41c8-b7a6-db4c63330ecf"
      },
      "source": [
        "early_stopping=EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                    batch_size=512,\n",
        "                    epochs=10,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1,\n",
        "                    callbacks=[early_stopping])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "319/319 [==============================] - 15s 40ms/step - loss: 0.5695 - accuracy: 0.6884 - val_loss: 0.4942 - val_accuracy: 0.7529\n",
            "Epoch 2/10\n",
            "319/319 [==============================] - 12s 39ms/step - loss: 0.2864 - accuracy: 0.8839 - val_loss: 0.5541 - val_accuracy: 0.7422\n",
            "Epoch 3/10\n",
            "319/319 [==============================] - 12s 39ms/step - loss: 0.0784 - accuracy: 0.9729 - val_loss: 0.7871 - val_accuracy: 0.7249\n",
            "Epoch 4/10\n",
            "319/319 [==============================] - 13s 40ms/step - loss: 0.0315 - accuracy: 0.9897 - val_loss: 0.9871 - val_accuracy: 0.7190\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQTTnhPCe_j7",
        "outputId": "597ba1b9-ba7e-4353-8702-4be4f9aad052"
      },
      "source": [
        "score = model.evaluate(X_valid, y_val, batch_size=512, verbose=0)\n",
        "print('\\n')\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "result.append(score)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Test loss: 0.5158835649490356\n",
            "Test accuracy: 0.7372922301292419\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M57DyX7IRFAu"
      },
      "source": [
        "**LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJCmTRvfe_os",
        "outputId": "413d66df-960c-4067-d417-70a085f36590"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(\n",
        "    Embedding(input_dim=word_count,\n",
        "              input_length=training_length,\n",
        "              output_dim=30,\n",
        "              trainable=True,\n",
        "              mask_zero=True))\n",
        "model.add(Masking(mask_value=0.0))\n",
        "model.add(LSTM(64, recurrent_dropout=0.2))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6y2JOEoIIvl6",
        "outputId": "01f95650-9a08-4865-c6eb-35816e73e6f2"
      },
      "source": [
        "early_stopping=EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)  \n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                    batch_size=512,\n",
        "                    epochs=10,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1,\n",
        "                    callbacks=[early_stopping])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "319/319 [==============================] - 37s 108ms/step - loss: 0.5556 - accuracy: 0.7051 - val_loss: 0.4936 - val_accuracy: 0.7528\n",
            "Epoch 2/10\n",
            "319/319 [==============================] - 34s 107ms/step - loss: 0.3288 - accuracy: 0.8638 - val_loss: 0.5429 - val_accuracy: 0.7452\n",
            "Epoch 3/10\n",
            "319/319 [==============================] - 34s 107ms/step - loss: 0.1629 - accuracy: 0.9391 - val_loss: 0.6759 - val_accuracy: 0.7334\n",
            "Epoch 4/10\n",
            "319/319 [==============================] - 35s 108ms/step - loss: 0.1017 - accuracy: 0.9630 - val_loss: 0.7813 - val_accuracy: 0.7288\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDcVShJTe_r_",
        "outputId": "81c9e4bb-2d60-47f6-a2d2-087491192ed2"
      },
      "source": [
        "score = model.evaluate(X_valid, y_val, batch_size=512, verbose=0)\n",
        "print('\\n')\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "result.append(score)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Test loss: 0.5072261691093445\n",
            "Test accuracy: 0.7461975812911987\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oy57N6THRIZN"
      },
      "source": [
        "**GRU**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfYl-YSMet56",
        "outputId": "30a42ffa-6c04-4d40-afac-8f563fc9ce0b"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(\n",
        "    Embedding(input_dim=word_count,\n",
        "              input_length=training_length,\n",
        "              output_dim=30,\n",
        "              trainable=True,\n",
        "              mask_zero=True))\n",
        "model.add(Masking(mask_value=0.0))\n",
        "model.add(GRU(64, recurrent_dropout=0.2))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAnfGQiaIq0w",
        "outputId": "96226c25-e305-4027-8da2-5bd3688a6d97"
      },
      "source": [
        "early_stopping=EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)  \n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                    batch_size=512,\n",
        "                    epochs=10,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1,\n",
        "                    callbacks=[early_stopping])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "319/319 [==============================] - 33s 97ms/step - loss: 0.5528 - accuracy: 0.7089 - val_loss: 0.4887 - val_accuracy: 0.7559\n",
            "Epoch 2/10\n",
            "319/319 [==============================] - 31s 96ms/step - loss: 0.3131 - accuracy: 0.8709 - val_loss: 0.5471 - val_accuracy: 0.7494\n",
            "Epoch 3/10\n",
            "319/319 [==============================] - 31s 96ms/step - loss: 0.1383 - accuracy: 0.9493 - val_loss: 0.6776 - val_accuracy: 0.7392\n",
            "Epoch 4/10\n",
            "319/319 [==============================] - 30s 95ms/step - loss: 0.0802 - accuracy: 0.9718 - val_loss: 0.8557 - val_accuracy: 0.7330\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3LcpJZmet83",
        "outputId": "1fdde23b-6555-4312-9425-dc8a520f472a"
      },
      "source": [
        "score = model.evaluate(X_valid, y_val, batch_size=512, verbose=0)\n",
        "print('\\n')\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "result.append(score)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Test loss: 0.516929030418396\n",
            "Test accuracy: 0.7403782606124878\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyqr0SP4Qwyf"
      },
      "source": [
        "### Сверточная сеть"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHKDFIeEet_O"
      },
      "source": [
        "embedding_layer = Embedding(input_dim=word_count, output_dim=30, input_length=training_length)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vR-oWTKlZJXp"
      },
      "source": [
        "sequence_input = Input(shape=(training_length,), dtype='int32')\n",
        "embedded_sequences = embedding_layer(sequence_input)\n",
        "x = Conv1D(128, 5, activation='relu', data_format='channels_first')(embedded_sequences)\n",
        "x = MaxPooling1D(5)(x)\n",
        "x = Conv1D(128, 5, activation='relu', data_format='channels_first')(x)\n",
        "x = MaxPooling1D(5)(x)\n",
        "x = Conv1D(128, 5, activation='relu', data_format='channels_first')(x)\n",
        "x = GlobalMaxPool1D()(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "preds = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(sequence_input, preds)\n",
        "model.compile(\n",
        "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXfWjAcjZJaj",
        "outputId": "51b179cb-895c-4de1-ee95-117fdf89b1a5"
      },
      "source": [
        "early_stopping=EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)  \n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                    batch_size=512,\n",
        "                    epochs=10,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1,\n",
        "                    callbacks=[early_stopping])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "319/319 [==============================] - 18s 9ms/step - loss: 0.5556 - accuracy: 0.6955 - val_loss: 0.4941 - val_accuracy: 0.7538\n",
            "Epoch 2/10\n",
            "319/319 [==============================] - 3s 8ms/step - loss: 0.2990 - accuracy: 0.8745 - val_loss: 0.5401 - val_accuracy: 0.7461\n",
            "Epoch 3/10\n",
            "319/319 [==============================] - 3s 8ms/step - loss: 0.0908 - accuracy: 0.9665 - val_loss: 0.7248 - val_accuracy: 0.7316\n",
            "Epoch 4/10\n",
            "319/319 [==============================] - 3s 8ms/step - loss: 0.0311 - accuracy: 0.9897 - val_loss: 0.9983 - val_accuracy: 0.7310\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVYOB0kMMLOH",
        "outputId": "be2474e5-c328-4c95-d50d-57e3c1aa4dcf"
      },
      "source": [
        "score = model.evaluate(X_valid, y_val, batch_size=512, verbose=0)\n",
        "print('\\n')\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "result.append(score)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Test loss: 0.5073196291923523\n",
            "Test accuracy: 0.7455363273620605\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiZgWFysQrqs"
      },
      "source": [
        "### Гибридная сеть"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDZwnJ58ZJi7"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=word_count,\n",
        "              input_length=training_length,\n",
        "              output_dim=30,\n",
        "              trainable=True,\n",
        "              mask_zero=True))\n",
        "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8QCO_pvZJlz",
        "outputId": "0b7298ab-07b5-4f4c-e500-28ac8ebd3096"
      },
      "source": [
        "early_stopping=EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)  \n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                    batch_size=512,\n",
        "                    epochs=10,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1,\n",
        "                    callbacks=[early_stopping])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "319/319 [==============================] - 5s 9ms/step - loss: 0.5564 - accuracy: 0.6991 - val_loss: 0.4895 - val_accuracy: 0.7568\n",
            "Epoch 2/10\n",
            "319/319 [==============================] - 2s 8ms/step - loss: 0.3000 - accuracy: 0.8742 - val_loss: 0.5351 - val_accuracy: 0.7468\n",
            "Epoch 3/10\n",
            "319/319 [==============================] - 2s 8ms/step - loss: 0.1182 - accuracy: 0.9559 - val_loss: 0.6960 - val_accuracy: 0.7360\n",
            "Epoch 4/10\n",
            "319/319 [==============================] - 2s 7ms/step - loss: 0.0573 - accuracy: 0.9801 - val_loss: 0.8511 - val_accuracy: 0.7336\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fy9bWhr9MRH7",
        "outputId": "b2af724b-a1c2-467f-ff76-17a92278e930"
      },
      "source": [
        "score = model.evaluate(X_valid, y_val, batch_size=512, verbose=0)\n",
        "print('\\n')\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "result.append(score)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Test loss: 0.5318854451179504\n",
            "Test accuracy: 0.7314288020133972\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0uZKKVVRL85"
      },
      "source": [
        "Значимого прироста в качестве гибридная сеть не дала"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7q6LtCpaUkS"
      },
      "source": [
        "**Посмотрим на результаты работы сетей**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "k4ns1ReNWKt1",
        "outputId": "af84d90c-fc31-4709-c4b3-3983588d77d3"
      },
      "source": [
        "networks = ['simpleRNN', 'LSTM', 'GRU', 'CNN', 'Hybrid']\n",
        "pd.DataFrame(result, index=networks, columns=['loss', 'accuracy'])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>simpleRNN</th>\n",
              "      <td>0.515884</td>\n",
              "      <td>0.737292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LSTM</th>\n",
              "      <td>0.507226</td>\n",
              "      <td>0.746198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GRU</th>\n",
              "      <td>0.516929</td>\n",
              "      <td>0.740378</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CNN</th>\n",
              "      <td>0.507320</td>\n",
              "      <td>0.745536</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Hybrid</th>\n",
              "      <td>0.531885</td>\n",
              "      <td>0.731429</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               loss  accuracy\n",
              "simpleRNN  0.515884  0.737292\n",
              "LSTM       0.507226  0.746198\n",
              "GRU        0.516929  0.740378\n",
              "CNN        0.507320  0.745536\n",
              "Hybrid     0.531885  0.731429"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeumeddvRawe"
      },
      "source": [
        "Как можно увидеть, значимых отличий не наблюдается. Но итоговый лучший результат у LSTM и CNN"
      ]
    }
  ]
}