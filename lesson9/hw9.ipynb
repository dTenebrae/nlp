{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw9.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1RyfNgqjRcPkIaw1omlBHBL2qHIV6GBf7",
      "authorship_tag": "ABX9TyOzWE9Ym7XayOJH0GYSFuUS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dTenebrae/nlp/blob/main/lesson9/hw9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cqq5_meuiZeX",
        "outputId": "b3314b96-427e-41c1-9b4d-db0346233035"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import datetime\n",
        "import re\n",
        "\n",
        "from tensorflow.python.client import device_lib\n",
        "print(f\"Tensorflow version: {tf.__version__}\")\n",
        "dev = re.findall(r\"name:\\W(.+),\", device_lib.list_local_devices()[1].physical_device_desc)[0].split(\",\")[0]\n",
        "print(f\"GPU: {dev}\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow version: 2.7.0\n",
            "GPU: Tesla P100-PCIE-16GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqZ8y-oYian6"
      },
      "source": [
        "with open(\"/content/drive/MyDrive/data/iliada.txt\") as f:\n",
        "    file_list = f.readlines()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "airksHWMiarI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfa8fad1-cdce-452f-e768-d27b2db45538"
      },
      "source": [
        "len(file_list)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "44569"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzWxQXECias9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3e633d7-93fd-491d-b8c3-a959eba71436"
      },
      "source": [
        "trimmed_text = []\n",
        "for line in file_list:\n",
        "    comp_line = re.findall(r\"[\\d\\s]+\", line)[0]\n",
        "    if (line != \"\\n\") and (line != comp_line):\n",
        "        line = line.replace(\"\\t\", \" \")\n",
        "        line = re.sub(r\"\\[\\d+\\]\", \"\", line)\n",
        "        trimmed_text.append(line)\n",
        "len(trimmed_text)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16845"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDrMB2Wziavh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e82fe155-0d01-42e6-82b6-c30dfb62ec9e"
      },
      "source": [
        "trimmed_text[:20]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Гомер\\n',\n",
              " 'Илиада\\n',\n",
              " 'Песнь первая\\n',\n",
              " 'Язва. Гнев\\n',\n",
              " 'Гнев, богиня,  воспой Ахиллеса,  Пелеева сына, Грозный, который ахеянам тысячи бедствий соделал:\\n',\n",
              " 'Многие души могучие славных героев низринул\\n',\n",
              " 'В мрачный Аид и самих распростер их в корысть плотоядным\\n',\n",
              " 'Птицам окрестным и псам (совершалася Зевсова воля), —\\n',\n",
              " 'С оного дня, как, воздвигшие спор, воспылали враждою\\n',\n",
              " 'Пастырь народов Атрид и герой Ахиллес благородный.\\n',\n",
              " 'Кто ж от богов бессмертных подвиг их к враждебному спору?\\n',\n",
              " 'Сын громовержца и Леты – Феб,  царем прогневленный,\\n',\n",
              " 'Язву на воинство злую навел; погибали народы\\n',\n",
              " 'В казнь, что Атрид обесчестил жреца непорочного Хриса.\\n',\n",
              " 'Старец, он приходил к кораблям быстролетным ахейским\\n',\n",
              " 'Пленную дочь искупить и, принесши бесчисленный выкуп\\n',\n",
              " 'И держа в руках, на жезле золотом, Аполлонов\\n',\n",
              " 'Красный венец,  умолял убедительно всех он ахеян, Паче ж Атридов могучих, строителей рати ахейской:\\n',\n",
              " '“Чада Атрея и пышнопоножные мужи ахейцы!\\n',\n",
              " 'О! да помогут вам боги, имущие домы в Олимпе, Град Приамов разрушить и счастливо в дом возвратиться;\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urE5elbNia3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39a7fbaf-a400-4c0e-f094-4a2485cac7fb"
      },
      "source": [
        "result = 0\n",
        "for line in trimmed_text:\n",
        "    result += len(line.split())\n",
        "print(f\"Number of tokens: {result}\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of tokens: 133448\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuHMustCia8n"
      },
      "source": [
        "joined_text = \"\".join(trimmed_text)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqhSQQSx9ptK",
        "outputId": "07e3228b-2ee6-44f7-b08b-7a6753288fdb"
      },
      "source": [
        "print(joined_text[:500])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Гомер\n",
            "Илиада\n",
            "Песнь первая\n",
            "Язва. Гнев\n",
            "Гнев, богиня,  воспой Ахиллеса,  Пелеева сына, Грозный, который ахеянам тысячи бедствий соделал:\n",
            "Многие души могучие славных героев низринул\n",
            "В мрачный Аид и самих распростер их в корысть плотоядным\n",
            "Птицам окрестным и псам (совершалася Зевсова воля), —\n",
            "С оного дня, как, воздвигшие спор, воспылали враждою\n",
            "Пастырь народов Атрид и герой Ахиллес благородный.\n",
            "Кто ж от богов бессмертных подвиг их к враждебному спору?\n",
            "Сын громовержца и Леты – Феб,  царем прогневленны\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-No1VHw9pvd",
        "outputId": "60676c26-2500-441e-8542-1523fbaa21b2"
      },
      "source": [
        "vocab = sorted(set(joined_text))\n",
        "print(f\"{len(vocab)} unique characters\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "106 unique characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NF5_wy79pxg",
        "outputId": "01c80a33-28f6-469b-a7bc-1c81e732a240"
      },
      "source": [
        "char2int = {c:i for i, c in enumerate(vocab)}\n",
        "int2char = np.array(vocab)\n",
        "for char,_ in zip(char2int, range(len(vocab))):\n",
        "    print(\"{:4s}: {:3d},\".format(repr(char), char2int[char]))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'\\n':   0,\n",
            "' ' :   1,\n",
            "'!' :   2,\n",
            "'(' :   3,\n",
            "')' :   4,\n",
            "',' :   5,\n",
            "'-' :   6,\n",
            "'.' :   7,\n",
            "'0' :   8,\n",
            "'1' :   9,\n",
            "'2' :  10,\n",
            "'3' :  11,\n",
            "'4' :  12,\n",
            "'5' :  13,\n",
            "'6' :  14,\n",
            "'7' :  15,\n",
            "'8' :  16,\n",
            "'9' :  17,\n",
            "':' :  18,\n",
            "';' :  19,\n",
            "'?' :  20,\n",
            "'B' :  21,\n",
            "'D' :  22,\n",
            "'E' :  23,\n",
            "'O' :  24,\n",
            "'T' :  25,\n",
            "'V' :  26,\n",
            "'a' :  27,\n",
            "'c' :  28,\n",
            "'e' :  29,\n",
            "'i' :  30,\n",
            "'l' :  31,\n",
            "'m' :  32,\n",
            "'n' :  33,\n",
            "'o' :  34,\n",
            "'s' :  35,\n",
            "'t' :  36,\n",
            "'u' :  37,\n",
            "'«' :  38,\n",
            "'»' :  39,\n",
            "'А' :  40,\n",
            "'Б' :  41,\n",
            "'В' :  42,\n",
            "'Г' :  43,\n",
            "'Д' :  44,\n",
            "'Е' :  45,\n",
            "'Ж' :  46,\n",
            "'З' :  47,\n",
            "'И' :  48,\n",
            "'К' :  49,\n",
            "'Л' :  50,\n",
            "'М' :  51,\n",
            "'Н' :  52,\n",
            "'О' :  53,\n",
            "'П' :  54,\n",
            "'Р' :  55,\n",
            "'С' :  56,\n",
            "'Т' :  57,\n",
            "'У' :  58,\n",
            "'Ф' :  59,\n",
            "'Х' :  60,\n",
            "'Ц' :  61,\n",
            "'Ч' :  62,\n",
            "'Ш' :  63,\n",
            "'Щ' :  64,\n",
            "'Э' :  65,\n",
            "'Ю' :  66,\n",
            "'Я' :  67,\n",
            "'а' :  68,\n",
            "'б' :  69,\n",
            "'в' :  70,\n",
            "'г' :  71,\n",
            "'д' :  72,\n",
            "'е' :  73,\n",
            "'ж' :  74,\n",
            "'з' :  75,\n",
            "'и' :  76,\n",
            "'й' :  77,\n",
            "'к' :  78,\n",
            "'л' :  79,\n",
            "'м' :  80,\n",
            "'н' :  81,\n",
            "'о' :  82,\n",
            "'п' :  83,\n",
            "'р' :  84,\n",
            "'с' :  85,\n",
            "'т' :  86,\n",
            "'у' :  87,\n",
            "'ф' :  88,\n",
            "'х' :  89,\n",
            "'ц' :  90,\n",
            "'ч' :  91,\n",
            "'ш' :  92,\n",
            "'щ' :  93,\n",
            "'ъ' :  94,\n",
            "'ы' :  95,\n",
            "'ь' :  96,\n",
            "'э' :  97,\n",
            "'ю' :  98,\n",
            "'я' :  99,\n",
            "'ё' : 100,\n",
            "'–' : 101,\n",
            "'—' : 102,\n",
            "'“' : 103,\n",
            "'”' : 104,\n",
            "'…' : 105,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHGdJnSH9p2p",
        "outputId": "0f05a614-6d38-48d5-966e-ecd3037cf876"
      },
      "source": [
        "text_as_int = np.array([char2int[ch] for ch in joined_text], dtype=np.int32)\n",
        "print(\"{}\\n mapped to integers:\\n {}\".format(repr(joined_text[:100]), text_as_int[:100]))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'Гомер\\nИлиада\\nПеснь первая\\nЯзва. Гнев\\nГнев, богиня,  воспой Ахиллеса,  Пелеева сына, Грозный, который'\n",
            " mapped to integers:\n",
            " [43 82 80 73 84  0 48 79 76 68 72 68  0 54 73 85 81 96  1 83 73 84 70 68\n",
            " 99  0 67 75 70 68  7  1 43 81 73 70  0 43 81 73 70  5  1 69 82 71 76 81\n",
            " 99  5  1  1 70 82 85 83 82 77  1 40 89 76 79 79 73 85 68  5  1  1 54 73\n",
            " 79 73 73 70 68  1 85 95 81 68  5  1 43 84 82 75 81 95 77  5  1 78 82 86\n",
            " 82 84 95 77]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIOLhyu3J9p3",
        "outputId": "a4b6c4dd-bab0-4849-9532-c78e701f3925"
      },
      "source": [
        "tr_text = text_as_int[:700_000] \n",
        "val_text = text_as_int[700_000:] \n",
        "print(text_as_int.shape, tr_text.shape, val_text.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(868003,) (700000,) (168003,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lu1hSsIwOCmW"
      },
      "source": [
        "batch_size = 64\n",
        "buffer_size = 10000\n",
        "embedding_dim = 256\n",
        "epochs = 50\n",
        "seq_length = 200\n",
        "examples_per_epoch = len(joined_text)//seq_length\n",
        "rnn_units = 1024\n",
        "vocab_size = len(vocab)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gihJyo_bOCpY",
        "outputId": "721458a3-0f86-4fe6-bb05-8b5cd4d83918"
      },
      "source": [
        "tr_char_dataset = tf.data.Dataset.from_tensor_slices(tr_text)\n",
        "val_char_dataset = tf.data.Dataset.from_tensor_slices(val_text)\n",
        "tr_sequences = tr_char_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "val_sequences = val_char_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "def split_input_target(chunk):\n",
        "    input_text = chunk[:-1]\n",
        "    target_text = chunk[1:]\n",
        "    return input_text, target_text\n",
        "    \n",
        "tr_dataset = tr_sequences.map(split_input_target).shuffle(buffer_size).batch(batch_size, drop_remainder=True)\n",
        "val_dataset = val_sequences.map(split_input_target).shuffle(buffer_size).batch(batch_size, drop_remainder=True)\n",
        "print(tr_dataset, val_dataset)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<BatchDataset shapes: ((64, 200), (64, 200)), types: (tf.int32, tf.int32)> <BatchDataset shapes: ((64, 200), (64, 200)), types: (tf.int32, tf.int32)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihxMewGTOCtc"
      },
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "    model = tf.keras.Sequential([\n",
        "                                 tf.keras.layers.Embedding(vocab_size, \n",
        "                                                           embedding_dim, \n",
        "                                                           batch_input_shape=[batch_size, None]),\n",
        "                                 tf.keras.layers.Dropout(0.2),\n",
        "                                 tf.keras.layers.LSTM(rnn_units, \n",
        "                                                      return_sequences=True, \n",
        "                                                      stateful=True, \n",
        "                                                      recurrent_initializer=\"glorot_uniform\"),\n",
        "                                 tf.keras.layers.Dropout(0.2), \n",
        "                                 tf.keras.layers.LSTM(rnn_units, \n",
        "                                                      return_sequences=True, \n",
        "                                                      stateful=True, \n",
        "                                                      recurrent_initializer=\"glorot_uniform\"),\n",
        "                                 tf.keras.layers.Dropout(0.2),\n",
        "                                 tf.keras.layers.Dense(vocab_size)\n",
        "                                  ])\n",
        "    return model"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_xMplgzccZV"
      },
      "source": [
        "model = build_model(\n",
        "    vocab_size = len(vocab),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units,\n",
        "    batch_size=batch_size\n",
        "    )"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbZxVnm7OCvz",
        "outputId": "fb676890-640d-48ca-8607-5a4169d43f13"
      },
      "source": [
        "model.summary()\n",
        "for input_example_batch, target_example_batch in tr_dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape)\n",
        "\n",
        "def loss(labels, logits):\n",
        "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "\n",
        "example_batch_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(f\"Loss: {example_batch_loss.numpy().mean()}\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (64, None, 256)           27136     \n",
            "                                                                 \n",
            " dropout (Dropout)           (64, None, 256)           0         \n",
            "                                                                 \n",
            " lstm (LSTM)                 (64, None, 1024)          5246976   \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (64, None, 1024)          0         \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (64, None, 1024)          8392704   \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (64, None, 1024)          0         \n",
            "                                                                 \n",
            " dense (Dense)               (64, None, 106)           108650    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,775,466\n",
            "Trainable params: 13,775,466\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "(64, 200, 106)\n",
            "Loss: 4.6642537117004395\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_n8ojglyOCyU"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "model.compile(optimizer=optimizer, loss=loss)\n",
        "patience = 10\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcAE8tbIljD1"
      },
      "source": [
        "checkpoint_dir = \"./checkpoints\"+ datetime.datetime.now().strftime(\"_%Y.%m.%d-%H:%M:%S\")\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7drxjBgOC0l",
        "outputId": "49a659aa-0393-440c-feaa-8d7f8b26b124"
      },
      "source": [
        "history = model.fit(tr_dataset, \n",
        "                    epochs=epochs, \n",
        "                    callbacks=[early_stop, checkpoint_callback] , \n",
        "                    validation_data=val_dataset)\n",
        "print(f\"Training stopped as there was no improvement after {patience} epochs\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "54/54 [==============================] - 19s 269ms/step - loss: 3.4352 - val_loss: 3.2678\n",
            "Epoch 2/50\n",
            "54/54 [==============================] - 14s 251ms/step - loss: 2.9747 - val_loss: 2.9469\n",
            "Epoch 3/50\n",
            "54/54 [==============================] - 15s 253ms/step - loss: 2.6218 - val_loss: 2.7975\n",
            "Epoch 4/50\n",
            "54/54 [==============================] - 15s 252ms/step - loss: 2.4227 - val_loss: 2.6518\n",
            "Epoch 5/50\n",
            "54/54 [==============================] - 15s 253ms/step - loss: 2.2514 - val_loss: 2.5169\n",
            "Epoch 6/50\n",
            "54/54 [==============================] - 15s 252ms/step - loss: 2.0762 - val_loss: 2.4126\n",
            "Epoch 7/50\n",
            "54/54 [==============================] - 15s 252ms/step - loss: 1.9197 - val_loss: 2.3152\n",
            "Epoch 8/50\n",
            "54/54 [==============================] - 14s 251ms/step - loss: 1.7926 - val_loss: 2.2268\n",
            "Epoch 9/50\n",
            "54/54 [==============================] - 15s 252ms/step - loss: 1.6923 - val_loss: 2.1722\n",
            "Epoch 10/50\n",
            "54/54 [==============================] - 14s 251ms/step - loss: 1.6102 - val_loss: 2.1254\n",
            "Epoch 11/50\n",
            "54/54 [==============================] - 15s 252ms/step - loss: 1.5446 - val_loss: 2.0941\n",
            "Epoch 12/50\n",
            "54/54 [==============================] - 15s 252ms/step - loss: 1.4889 - val_loss: 2.0702\n",
            "Epoch 13/50\n",
            "54/54 [==============================] - 15s 253ms/step - loss: 1.4406 - val_loss: 2.0516\n",
            "Epoch 14/50\n",
            "54/54 [==============================] - 15s 252ms/step - loss: 1.3971 - val_loss: 2.0438\n",
            "Epoch 15/50\n",
            "54/54 [==============================] - 15s 252ms/step - loss: 1.3551 - val_loss: 2.0349\n",
            "Epoch 16/50\n",
            "54/54 [==============================] - 15s 252ms/step - loss: 1.3165 - val_loss: 2.0244\n",
            "Epoch 17/50\n",
            "54/54 [==============================] - 14s 251ms/step - loss: 1.2771 - val_loss: 2.0250\n",
            "Epoch 18/50\n",
            "54/54 [==============================] - 14s 251ms/step - loss: 1.2391 - val_loss: 2.0294\n",
            "Epoch 19/50\n",
            "54/54 [==============================] - 15s 251ms/step - loss: 1.2028 - val_loss: 2.0373\n",
            "Epoch 20/50\n",
            "54/54 [==============================] - 14s 251ms/step - loss: 1.1633 - val_loss: 2.0480\n",
            "Epoch 21/50\n",
            "54/54 [==============================] - 15s 251ms/step - loss: 1.1262 - val_loss: 2.0632\n",
            "Epoch 22/50\n",
            "54/54 [==============================] - 14s 251ms/step - loss: 1.0890 - val_loss: 2.0795\n",
            "Epoch 23/50\n",
            "54/54 [==============================] - 14s 252ms/step - loss: 1.0517 - val_loss: 2.0969\n",
            "Epoch 24/50\n",
            "54/54 [==============================] - 15s 253ms/step - loss: 1.0120 - val_loss: 2.1155\n",
            "Epoch 25/50\n",
            "54/54 [==============================] - 15s 252ms/step - loss: 0.9766 - val_loss: 2.1334\n",
            "Epoch 26/50\n",
            "54/54 [==============================] - 15s 253ms/step - loss: 0.9388 - val_loss: 2.1591\n",
            "Training stopped as there was no improvement after 10 epochs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqo4B7r-OC3G",
        "outputId": "326b6cad-0eba-469b-b95d-5e35110369a0"
      },
      "source": [
        "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir)) \n",
        "model.build(tf.TensorShape([1, None]))\n",
        "def generate_text(model, start_string):\n",
        "    print('Generating with seed: \"' + start_string + '\"')\n",
        "  \n",
        "    num_generate = 1000\n",
        "    input_eval = [char2int[s] for s in start_string]\n",
        "    input_eval = tf.expand_dims(input_eval, 0)\n",
        "    text_generated = []\n",
        "    temperature = 1.0\n",
        "    model.reset_states()\n",
        "    for i in range(num_generate):\n",
        "        predictions = model(input_eval)\n",
        "        predictions = tf.squeeze(predictions, 0)\n",
        "        predictions = predictions / temperature\n",
        "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "        input_eval = tf.expand_dims([predicted_id], 0)\n",
        "        text_generated.append(int2char[predicted_id])\n",
        "    return (start_string + ''.join(text_generated))\n",
        "\n",
        "print(generate_text(model, start_string=\"В мрачный Аид и самих\"))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating with seed: \"В мрачный Аид и самих\"\n",
            "В мрачный Аид и самихов и духом предстал он:\n",
            "“Храбрый если обоих ты оставь совершенно издебренновно?\n",
            "Если ж ты, уже в сражению! Дордую мчатся\n",
            "Вслад пред тобой поражают Менета и смертных супруга.\n",
            "Если б эни бы справедли глабокий малает, Тера, Анфимеха Аргоса грома, смира в челоезате, —\n",
            "Я на тебя улылого, возвести мне я, повелимом\n",
            "Я в илион по\n",
            "пошлюд и кразешь их деня изло многих.\n",
            "Рек Лиимоп, и сама обращенно вершине, —\n",
            "Так произнес – на другое что дивную славу я буду!\n",
            "Зовчу на Идошей медь, сердца то жилость вещаешь?\n",
            "Так он Тевфон, поразила в противенной руки Арея.\n",
            "Тою порою прили, за полу волна Троа слушаться!\n",
            "Истинно сына и разра, помодит и могущество духа,\n",
            "Мужа величесь цвего, как своед корабли их давесца\n",
            "Коней черного не будет великая смертного сына.\n",
            "Тов, лишь Афина сыны виношил, но презренные дени\n",
            "В вые от Зевса героя, чудос на свирепстве его злопотучное рато;\n",
            "Гактора матерь любезная: медь ты сыны беспрестанно\n",
            "Паден тельцов ни бесполнить безумно бессмертным.\n",
            "Он повелел он, когда из троянам хитонов лежал\n"
          ]
        }
      ]
    }
  ]
}